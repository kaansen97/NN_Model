# -*- coding: utf-8 -*-
"""Sen_Kaan_Deep_Learning_Assignment_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12qoWyDz3CUGAGdRPqQcbvdbIaSUdRmBU
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torchvision as tv

import numpy as np
np.set_printoptions(suppress=True)
import matplotlib.pyplot as plt
import random

# See https://pytorch.org/docs/stable/notes/randomness.html
# Often, these are still not enough to exactly reproduce results
torch.manual_seed(0)
np.random.seed(0)

if torch.cuda.is_available():
    torch.cuda.manual_seed_all(0)
    # torch.backends.cudnn.deterministic = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

"""# **Exercise 2**"""

# Hyper-parameters 
input_size = 1024
hidden_size = 512
num_classes = 10

# for training:
batch_size = 32
learning_rate = 0.001
momentum = 0.9

transform=transforms.Compose( [transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465),
      (0.247, 0.243, 0.261))])

train_set = torchvision.datasets.CIFAR10(
    root='./data', train=True, transform=transform, download=True)

test_set = torchvision.datasets.CIFAR10(
    root='./data', train=False,transform=transform)

# Dataloaders
test_loader = torch.utils.data.DataLoader(
    dataset=test_set, batch_size=batch_size, shuffle=False)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

"""# **Exercise 3 BONUS**"""

cifar_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())

imgs = [item[0] for item in cifar_trainset] # item[0] and item[1] are image and its label
imgs = torch.stack(imgs, dim=0).numpy()

# calculate mean over each channel (r,g,b)
mean_r = imgs[:,0,:,:].mean()
mean_g = imgs[:,1,:,:].mean()
mean_b = imgs[:,2,:,:].mean()
print('Mean of Red :'+str(mean_r),'\n Mean of Green :'+str(mean_g),'\n Mean of Blue :'+str(mean_b))

# calculate std over each channel (r,g,b)
std_r = imgs[:,0,:,:].std()
std_g = imgs[:,1,:,:].std()
std_b = imgs[:,2,:,:].std()
print('Std of Red :'+str(std_r),'\n Std of Green :'+str(std_g),'\n Std of Blue :'+str(std_b))

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

"""# **We can verify that given mean and std values are correct**"""

from IPython.testing import test
print("Train set :",len(train_set),"\n Test set :",len(test_set))

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

"""# **Exercice 1**"""

# get some random training images
#dataiter = iter(train_set)
#images, classes = next(dataiter)
for i in range(44,48):
     
     dataiter = iter(train_set[i])
     images= next(dataiter)
     #show images
     imshow(torchvision.utils.make_grid(images))

"""# **Exercice 4**"""

idx = np.arange(len(train_set))

# Use last 1000 images for validation
val_indices = idx[50000-1000:]
train_indices= idx[:-1000]

print("Validation size : ",len(val_indices))
print("Training size : ",len(train_indices))

train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)
valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=train_sampler, num_workers=2)

valid_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=valid_sampler, num_workers=2)

class CNNModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(CNNModel, self).__init__()
        
        self.conv1 = nn.Conv2d(3 ,32,3)
        self.conv2 = nn.Conv2d(32 ,32,3)
        self.pool1 = nn.MaxPool2d(2,2)
        self.conv3 = nn.Conv2d(32 ,64,3)
        self.conv4 = nn.Conv2d(64 ,64,3)
        self.pool2 = nn.MaxPool2d(2,2)
        self.fc = nn.Linear(64*5*5,512)
        self.out = nn.Linear(512,num_classes)
        self.activation = nn.ReLU(inplace=True)

    def forward(self, x):

        x = self.conv1(x)
        x = F.relu(x)

        x = self.conv2(x)
        x = F.relu(x)

        x = self.pool1(x)

        x = self.conv3(x)
        x = F.relu(x)

        x = self.conv4(x)
        x = F.relu(x)
        x = self.pool2(x)

        x = torch.flatten(x, 1)
        x = self.fc(x)               
        x = self.out(x)

        return x

model = CNNModel(input_size , hidden_size , num_classes)
model = model.to(device)  # put all model params on GPU.

# Create loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

print(model)

"""# **3.1 Training Pipeline**"""

# Training
val_losses = []
train_losses = []
epoch_valloss=[]
train_acc=[]
val_acc=[]
num_epochs = 20

for epoch in range(1, num_epochs):
    running_loss = 0.0
    running_total = 0
    running_correct = 0
    run_step = 0
    corrects=0
    for i, (images, labels) in enumerate(train_loader):
        model.train()  # put the model to train mode
        # shape of input images is (B, 3, 32, 32).
        images = images.to(device)
        labels = labels.to(device)  # shape (B).
        outputs = model(images)  # shape (B, 10).
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()  # reset gradients.
        loss.backward()  # compute gradients.
        optimizer.step()  # update parameters.

        running_loss += loss.item()
        running_total += labels.size(0)

        

        with torch.no_grad():
            _, predicted = outputs.max(1)
        running_correct += (predicted == labels).sum().item()
        run_step += 1
        
        
        
        if i % 200 == 0:
            # check accuracy.
            print(f'epoch: {epoch}, steps: {i}, '
                  f'train_loss: {running_loss / run_step :.3f}, '
                  f'running_acc: {100 * running_correct / running_total:.1f} %')
            
            train_acc.append(100*(running_correct / running_total))
            train_losses.append(running_loss/run_step)
            
            running_loss = 0.0
            running_total = 0
            running_correct = 0
            run_step = 0



    # validation
    correct = 0
    total = 0
    model.eval()
    with torch.no_grad():
        for data in valid_loader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = outputs.max(1)
            
            #Validation Loss
            val_loss=loss_fn(outputs,labels)
            epoch_valloss.append(val_loss.item())
            val_losses.append(sum(epoch_valloss)/len(epoch_valloss))

            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            val_acc.append(100*correct / total)
    # NB: : .1f specifies that you want 1 floating point
    print(f'Validation accuracy: {100 * correct / total: .1f} %')
print('Finished Training')

PATH = './cifar_net_v1.pth'
torch.save(model.state_dict(), PATH)

len(val_losses)

k=0
resized_losses=[]
resized_acc=[]
for i in range(0,608,4):
          resized_losses.append(val_losses[i]+val_losses[i+1]+val_losses[i+2]+val_losses[i+3])
          resized_losses[k]=resized_losses[k]/4
          resized_acc.append(val_acc[i]+val_acc[i+1]+val_acc[i+2]+val_acc[i+3])
          resized_acc[k]=resized_acc[k]/4
          k=k+1

print(len(resized_losses),len(train_losses))

#plt.plot(train_losses,label="Training Loss")
plt.plot(train_acc,label="Training Accuracy")
plt.plot(resized_acc,label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

plt.plot(train_losses,label="Training Loss")
plt.plot(resized_losses,label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

class CNNModelDrop(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(CNNModelDrop, self).__init__()
        
        self.conv1 = nn.Conv2d(3 ,32,3)
        self.conv2 = nn.Conv2d(32 ,32,3)
        self.pool1 = nn.MaxPool2d(2,2)
        self.drop1 = nn.Dropout(p=0.5,inplace=False)
        self.conv3 = nn.Conv2d(32 ,64,3)
        self.conv4 = nn.Conv2d(64 ,64,3)
        self.pool2 = nn.MaxPool2d(2,2)
        self.drop2 = nn.Dropout(p=0.5,inplace=False)
        self.fc = nn.Linear(64*5*5,512)
        self.out = nn.Linear(512,num_classes)
        self.activation = nn.ReLU(inplace=True)

    def forward(self, x):

        x = self.conv1(x)
        x = F.relu(x)

        x = self.conv2(x)
        x = F.relu(x)

        x = self.pool1(x)
        x = self.drop1(x)

        x = self.conv3(x)
        x = F.relu(x)

        x = self.conv4(x)
        x = F.relu(x)
        x = self.pool2(x)
        x = self.drop2(x)

        x = torch.flatten(x, 1)
        x = self.fc(x)               
        x = self.out(x)

        return x

modelD = CNNModelDrop(input_size , hidden_size , num_classes)
modelD = modelD.to(device)  # put all model params on GPU.

# Create loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(modelD.parameters(), lr=learning_rate, momentum=momentum)

print(modelD)

# Training
drop_val_losses = []
drop_train_losses = []
drop_epoch_valloss=[]
drop_train_acc=[]
drop_val_acc=[]
num_epochs = 29

for epoch in range(1, num_epochs):
    running_loss = 0.0
    running_total = 0
    running_correct = 0
    run_step = 0
    corrects=0
    for i, (images, labels) in enumerate(train_loader):
        modelD.train()  # put the model to train mode
        # shape of input images is (B, 3, 32, 32).
        images = images.to(device)
        labels = labels.to(device)  # shape (B).
        outputs = modelD(images)  # shape (B, 10).
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()  # reset gradients.
        loss.backward()  # compute gradients.
        optimizer.step()  # update parameters.

        running_loss += loss.item()
        running_total += labels.size(0)

        

        with torch.no_grad():
            _, predicted = outputs.max(1)
        running_correct += (predicted == labels).sum().item()
        run_step += 1
        if i % 200 == 0:
            # check accuracy.
            print(f'epoch: {epoch}, steps: {i}, '
                  f'train_loss: {running_loss / run_step :.3f}, '
                  f'running_acc: {100 * running_correct / running_total:.1f} %')
            
            drop_train_acc.append(100*running_correct / running_total)
            drop_train_losses.append(running_loss/run_step)
            
            running_loss = 0.0
            running_total = 0
            running_correct = 0
            run_step = 0


    # validation
    correct = 0
    total = 0
    modelD.eval()
    with torch.no_grad():
        for data in valid_loader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = modelD(images)
            _, predicted = outputs.max(1)
            #Validation Loss
            drop_val_loss=loss_fn(outputs,labels)
            drop_epoch_valloss.append(drop_val_loss.item())
            drop_val_losses.append(sum(drop_epoch_valloss)/len(drop_epoch_valloss))

            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            drop_val_acc.append(100 * correct / total)
    # NB: : .1f specifies that you want 1 floating point
    print(f'Validation accuracy: {100 * correct / total: .1f} %')
print('Finished Training')

k=0
drop_resized_losses=[]
drop_resized_acc=[]
for i in range(0,896,4):
    drop_resized_losses.append(drop_val_losses[i]+drop_val_losses[i+1]+drop_val_losses[i+2]+drop_val_losses[i+3])
    drop_resized_losses[k]=drop_resized_losses[k]/4
    drop_resized_acc.append(drop_val_acc[i]+drop_val_acc[i+1]+drop_val_acc[i+2]+drop_val_acc[i+3])
    drop_resized_acc[k]=drop_resized_acc[k]/4
    k=k+1

plt.figure(figsize=(10,5))
plt.plot(drop_train_losses,label="Training Loss")
plt.plot(drop_resized_losses,label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.figure(figsize=(10,5))
plt.plot(drop_train_acc,label="Training Accuracy")
plt.plot(drop_resized_acc,label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# Test
    correct = 0
    total = 0
    modelD.eval()
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = modelD(images)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    # NB: : .1f specifies that you want 1 floating point
    print(f'Test accuracy: {100 * correct / total: .1f} %')

import numpy as np
dataiter = iter(valid_loader)
images, labels = next(dataiter)

# print images
high=np.random.randint(4,len(images))
imshow(torchvision.utils.make_grid(images[high-4:high]))
print('Classes: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(high-4,high)))

image4=[]
image4=images[high-4:high]
classes4=[]
classes4.append(classes[labels[j]]for j in range(high-4,high))

with torch.no_grad():
    modelD.eval()
    image4 = image4.to(device)
    output = modelD(image4)            
    sm = torch.nn.Softmax(dim=1)
    probabilities = sm(output)

import pandas as pd
probabilities=probabilities.cpu()
df=pd.DataFrame(probabilities.detach().numpy(),columns=classes)
df

imshow(torchvision.utils.make_grid(image4[0].cpu()))
print("Probability distribution of",classes[labels[high-4]])
df.T[0].plot.bar();

imshow(torchvision.utils.make_grid(image4[1].cpu()))
print("Probability distribution of ",classes[labels[high-3]])
df.T[1].plot.bar();

imshow(torchvision.utils.make_grid(image4[2].cpu()))
print("Probability distribution of",classes[labels[high-2]])
df.T[2].plot.bar();

imshow(torchvision.utils.make_grid(image4[3].cpu()))
print("Probability distribution of",classes[labels[high-1]])
df.T[3].plot.bar();

class CNNImp(nn.Module):
   

    
    def __init__(self, input_size, hidden_size, num_classes):
        super(CNNImp, self).__init__()

        self.conv_layer = nn.Sequential(

            # Conv Layer block 1
            nn.Conv2d(3,32,3),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(32,64,3),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool2d(2,2),
            nn.Dropout2d(p=0.05),

            # Conv Layer block 2
            nn.Conv2d(64,256,3),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(256,128,3),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool2d(2,2),
            nn.Dropout2d(p=0.05),
        )

        self.fc_layer = nn.Sequential(
           #nn.Dropout(p=0.1),
            nn.Linear(3200, 1024),
            nn.LeakyReLU(inplace=True),
            nn.Linear(1024, 512),
            nn.LeakyReLU(inplace=True),
#             nn.Dropout(p=0.1),
            nn.Linear(512, 10)
        )


    def forward(self, x):
        """Perform forward."""
        
        # conv layers
        x = self.conv_layer(x)
        
        # flatten
        x = x.view(x.size(0), -1)
        # fc layer
        x = self.fc_layer(x)

        return x

model_V2 = CNNImp(input_size , hidden_size , num_classes)
model_V2 = model_V2.to(device)  # put all model params on GPU.

# Create loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model_V2.parameters(), lr=learning_rate, momentum=momentum)

print(model_V2)

# Training

imp_val_losses = []
imp_train_losses = []
imp_epoch_train_losses=[]
imp_epoch_valloss=[]
imp_train_acc=[]
imp_val_acc=[]

num_epochs = 15

for epoch in range(1, num_epochs):
    running_loss = 0.0
    running_total = 0
    running_correct = 0
    run_step = 0
    corrects=0
    for i, (images, labels) in enumerate(train_loader):
        model_V2.train()  # put the model to train mode
        # shape of input images is (B, 3, 32, 32).
        images = images.to(device)
        labels = labels.to(device)  # shape (B).
        outputs = model_V2(images)  # shape (B, 10).
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()  # reset gradients.
        loss.backward()  # compute gradients.
        optimizer.step()  # update parameters.

        running_loss += loss.item()
        running_total += labels.size(0)

        

        with torch.no_grad():
            _, predicted = outputs.max(1)
        running_correct += (predicted == labels).sum().item()
        run_step += 1
        if i % 200 == 0:
            # check accuracy.
            print(f'epoch: {epoch}, steps: {i}, '
                  f'train_loss: {running_loss / run_step :.3f}, '
                  f'running_acc: {100 * running_correct / running_total:.1f} %')
            
            imp_train_acc.append(100*running_correct / running_total)
            imp_epoch_train_losses.append(loss.item())
            imp_train_losses.append(sum(imp_epoch_train_losses)/len(imp_epoch_train_losses))
            
            running_loss = 0.0
            running_total = 0
            running_correct = 0
            run_step = 0


            


    # validation
    correct = 0
    total = 0
    model_V2.eval()
    with torch.no_grad():
        for data in valid_loader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = model_V2(images)
            _, predicted = outputs.max(1)
            #Validation Loss
            imp_val_loss=loss_fn(outputs,labels)
            imp_epoch_valloss.append(imp_val_loss.item())
            imp_val_losses.append(sum(imp_epoch_valloss)/len(imp_epoch_valloss))
           
            
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            imp_val_acc.append(100 * correct / total)
            # NB: : .1f specifies that you want 1 floating point
        print(f'Validation accuracy: {100 * correct / total: .1f} %')


              
print('Finished Training')

# Test
correct = 0
total = 0
model_V2.eval()
with torch.no_grad():
      for data in test_loader:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = model_V2(images)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print(f'Test accuracy: {100 * correct / total: .1f} %')

k=0
imp_resized_losses=[]
imp_resized_acc=[]
for i in range(0,448,4):
    imp_resized_losses.append(imp_val_losses[i]+imp_val_losses[i+1]+imp_val_losses[i+2]+imp_val_losses[i+3])
    imp_resized_losses[k]=imp_resized_losses[k]/4
    imp_resized_acc.append(imp_val_acc[i]+imp_val_acc[i+1]+imp_val_acc[i+2]+imp_val_acc[i+3])
    imp_resized_acc[k]=imp_resized_acc[k]/4
    k=k+1

print(len(imp_train_losses),len(imp_val_losses))

plt.figure(figsize=(10,5))
plt.plot(imp_train_losses,label="Training Loss")
plt.plot(imp_resized_losses,label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.figure(figsize=(10,5))
plt.plot(imp_train_acc,label="Training Accuracy")
plt.plot(imp_resized_acc,label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

PATH = './cifar_net_Imp.pth'
torch.save(modelD.state_dict(), PATH)